{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RetinaNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPkUF/y/ZJ59zy/ZoCSIVuv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jugal-krishna/Object-detection/blob/main/RetinaNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Retinanet_R_50_FPN***"
      ],
      "metadata": {
        "id": "HI5E-P5yd5Cz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edwomTurdypy"
      },
      "outputs": [],
      "source": [
        "# Install detectron\n",
        "\n",
        "!pip install detectron2 -f \\\n",
        "  https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/index.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "\n",
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.data import build_detection_test_loader\n",
        "from detectron2.evaluation import inference_on_dataset, PascalVOCDetectionEvaluator"
      ],
      "metadata": {
        "id": "BJFioOPFeFDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download datasets\n",
        "\n",
        "!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
        "!tar -xvf VOCtrainval_06-Nov-2007.tar\n",
        "!mv VOCdevkit datasets  "
      ],
      "metadata": {
        "id": "0XEnkMgVeF5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize an image\n",
        "\n",
        "im = cv2.imread(\"/content/datasets/VOC2007/JPEGImages/000005.jpg\")\n",
        "cv2_imshow(im)"
      ],
      "metadata": {
        "id": "HxsSsjA0eH1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurations\n",
        "\n",
        "cfg = get_cfg() \n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\"))\n",
        "cfg.OUTPUT_DIR = 'MyVOCTraining_retinanet_R_50_FPN_3x'\n",
        "cfg.DATASETS.TRAIN = (\"voc_2007_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 1\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_50_FPN_3x.yaml\") # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 1\n",
        "cfg.SOLVER.BASE_LR = 0.00025 # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 3000 \n",
        "cfg.MODEL.RETINANET.BATCH_SIZE_PER_IMAGE = 128 \n",
        "cfg.MODEL.RETINANET.NUM_CLASSES = 20"
      ],
      "metadata": {
        "id": "qvgZcJ7aeMPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with the above configurations\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "CotrKD6oeTiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at training curves in tensorboard:\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir MyVOCTraining"
      ],
      "metadata": {
        "id": "zI2F6LtSeVQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
        "val_dataset = 'voc_2007_val'\n",
        "\n",
        "# Validation\n",
        "\n",
        "\n",
        "voc_evaluator = PascalVOCDetectionEvaluator(val_dataset)\n",
        "val_dataloader = build_detection_test_loader(cfg, val_dataset)\n",
        "predictor = DefaultPredictor(cfg)\n",
        "inference_on_dataset(predictor.model, val_dataloader, voc_evaluator)['bbox']['AP50']"
      ],
      "metadata": {
        "id": "RxEf1xIGeY5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing some outputs\n",
        "\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "val_img = DatasetCatalog.get(\"voc_2007_val\")\n",
        "\n",
        "for d in random.sample(val_img, 7):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata= MetadataCatalog.get('voc_2007_train'), \n",
        "                   scale= 1.2\n",
        "      )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "HSRwPoWVebCp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}